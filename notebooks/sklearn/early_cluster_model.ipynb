{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "import requests, os, sys\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, confusion_matrix\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import linear_model, svm, naive_bayes, neighbors, ensemble\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_seq_items', 1000)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# calling bitcoin heist data\n",
    "df = pd.read_csv('../../../data/external/BitcoinHeistData.csv').rename(columns = {'label':'ransomware'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['princetonCerber',\n",
       " 'princetonLocky',\n",
       " 'montrealCryptoLocker',\n",
       " 'montrealCryptXXX',\n",
       " 'paduaCryptoWall',\n",
       " 'montrealWannaCry',\n",
       " 'montrealDMALockerv3',\n",
       " 'montrealCryptoTorLocker2015',\n",
       " 'montrealSamSam',\n",
       " 'montrealFlyper',\n",
       " 'montrealNoobCrypt',\n",
       " 'montrealDMALocker',\n",
       " 'montrealGlobe',\n",
       " 'montrealEDA2',\n",
       " 'paduaKeRanger',\n",
       " 'montrealVenusLocker',\n",
       " 'montrealXTPLocker',\n",
       " 'paduaJigsaw',\n",
       " 'montrealGlobev3',\n",
       " 'montrealJigSaw',\n",
       " 'montrealXLockerv5.0',\n",
       " 'montrealXLocker',\n",
       " 'montrealRazy',\n",
       " 'montrealCryptConsole',\n",
       " 'montrealGlobeImposter',\n",
       " 'montrealSam',\n",
       " 'montrealComradeCircle',\n",
       " 'montrealAPT',\n",
       " 'white']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find list of ransomwares\n",
    "ransomwares = df.ransomware.unique().tolist()\n",
    "\n",
    "ransomwares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## CHOOSE LABELS HERE\n",
    "labels = [\n",
    "             'montrealCryptoLocker',\n",
    "             'paduaCryptoWall'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# column for adding label\n",
    "def add_label(row):\n",
    "    if row['ransomware'] in labels:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# adding label\n",
    "df['label'] = df.apply(add_label, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# reordering columns\n",
    "df = df[['label', 'ransomware'] + [col for col in df.columns if col not in ['label', 'ransomware']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2894992\n",
       "1      21705\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the counts of each label\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    99.255836\n",
       "1     0.744164\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the percentage of each label\n",
    "df.label.value_counts()/df.label.count()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>ransomware</th>\n",
       "      <th>address</th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>length</th>\n",
       "      <th>weight</th>\n",
       "      <th>count</th>\n",
       "      <th>looped</th>\n",
       "      <th>neighbors</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>princetonCerber</td>\n",
       "      <td>111K8kZAEnJg245r2cM6y9zgJGHZtJPy6</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>100050000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>princetonLocky</td>\n",
       "      <td>1123pJv8jzeFQaCV4w644pzQJzVWay2zcA</td>\n",
       "      <td>2016</td>\n",
       "      <td>132</td>\n",
       "      <td>44</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>princetonCerber</td>\n",
       "      <td>112536im7hy6wtKbpH1qYDWtTyMRAcA2p7</td>\n",
       "      <td>2016</td>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>200000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>princetonCerber</td>\n",
       "      <td>1126eDRw2wqSkWosjTCre8cjjQW8sSeWH7</td>\n",
       "      <td>2016</td>\n",
       "      <td>322</td>\n",
       "      <td>72</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>71200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>princetonLocky</td>\n",
       "      <td>1129TSjKtx65E35GiUo4AYVeyo48twbrGX</td>\n",
       "      <td>2016</td>\n",
       "      <td>238</td>\n",
       "      <td>144</td>\n",
       "      <td>0.072848</td>\n",
       "      <td>456</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>200000000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label       ransomware                             address  year  day  \\\n",
       "0      0  princetonCerber   111K8kZAEnJg245r2cM6y9zgJGHZtJPy6  2017   11   \n",
       "1      0   princetonLocky  1123pJv8jzeFQaCV4w644pzQJzVWay2zcA  2016  132   \n",
       "2      0  princetonCerber  112536im7hy6wtKbpH1qYDWtTyMRAcA2p7  2016  246   \n",
       "3      0  princetonCerber  1126eDRw2wqSkWosjTCre8cjjQW8sSeWH7  2016  322   \n",
       "4      0   princetonLocky  1129TSjKtx65E35GiUo4AYVeyo48twbrGX  2016  238   \n",
       "\n",
       "   length    weight  count  looped  neighbors       income  \n",
       "0      18  0.008333      1       0          2  100050000.0  \n",
       "1      44  0.000244      1       0          1  100000000.0  \n",
       "2       0  1.000000      1       0          2  200000000.0  \n",
       "3      72  0.003906      1       0          2   71200000.0  \n",
       "4     144  0.072848    456       0          1  200000000.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# selecting dates appropriate for cerber\n",
    "df = df[(df['year'] >= 2013) & (df['year'] <= 2015)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sorting values by time\n",
    "df = df.sort_values(by=['year', 'day']).reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>ransomware</th>\n",
       "      <th>address</th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>length</th>\n",
       "      <th>weight</th>\n",
       "      <th>count</th>\n",
       "      <th>looped</th>\n",
       "      <th>neighbors</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>montrealCryptoLocker</td>\n",
       "      <td>16cVG72goMe4sNqZhnpmnqfCMZ1uSFbUit</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>65500000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>montrealCryptoLocker</td>\n",
       "      <td>1BCRuRA9mgVuhSkLBgvVrgSP6MZ3ri9Xrt</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>4.768372e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47569450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>montrealCryptoLocker</td>\n",
       "      <td>1BzhCdy3TtFJoYqd6fFdYFkPLz3phzxK6Y</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>9.765625e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>montrealCryptoLocker</td>\n",
       "      <td>1NGtvWJUuFEq2wma5YEi9n3TD7EDUj1LjU</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9.844322e-03</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50311924.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>white</td>\n",
       "      <td>1onFsTV86TP3PqyMfRHb4idcy1AskVo6m</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>3.125000e-02</td>\n",
       "      <td>1217</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>73835034.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label            ransomware                             address  year  day  \\\n",
       "0      1  montrealCryptoLocker  16cVG72goMe4sNqZhnpmnqfCMZ1uSFbUit  2013    1   \n",
       "1      1  montrealCryptoLocker  1BCRuRA9mgVuhSkLBgvVrgSP6MZ3ri9Xrt  2013    1   \n",
       "2      1  montrealCryptoLocker  1BzhCdy3TtFJoYqd6fFdYFkPLz3phzxK6Y  2013    1   \n",
       "3      1  montrealCryptoLocker  1NGtvWJUuFEq2wma5YEi9n3TD7EDUj1LjU  2013    1   \n",
       "4      0                 white   1onFsTV86TP3PqyMfRHb4idcy1AskVo6m  2013    1   \n",
       "\n",
       "   length        weight  count  looped  neighbors      income  \n",
       "0       0  5.000000e-01      1       0          2  65500000.0  \n",
       "1      78  4.768372e-07      1       0          1  47569450.0  \n",
       "2      38  9.765625e-04      1       0          1  34000000.0  \n",
       "3       6  9.844322e-03      4       0          1  50311924.0  \n",
       "4      90  3.125000e-02   1217       0          2  73835034.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw training data size: 893212, Raw testing data size: 223302\n"
     ]
    }
   ],
   "source": [
    "# SET TEST SIZE HERE\n",
    "test_size = 0.2\n",
    "train_size = int(df.shape[0]*(1-test_size))\n",
    "\n",
    "raw_train_df = df[df.index <= train_size]\n",
    "raw_test_df = df[df.index > train_size]\n",
    "\n",
    "print(f'Raw training data size: {raw_train_df.shape[0]}, Raw testing data size: {raw_test_df.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Balancing training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    97.98133\n",
       "1     2.01867\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the percentage of each label \n",
    "raw_train_df.label.value_counts()/raw_train_df.label.count()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# isolate labelled data\n",
    "label_train_df = raw_train_df[raw_train_df.label == 1]\n",
    "label_train_size = label_train_df.label.count()\n",
    "\n",
    "# isolate unlabelled data\n",
    "unlabel_train_df = raw_train_df[raw_train_df.label == 0]\n",
    "\n",
    "# sample unlabelled data to equal the size of the labelled data\n",
    "reduced_unlabel_train_df = unlabel_train_df.sample(n=label_train_size, random_state=11)\n",
    "\n",
    "# combine to make final training data\n",
    "train_df = (pd.concat([label_train_df, reduced_unlabel_train_df])\n",
    "                        .sort_values(by=['year', 'day'])\n",
    "                        .reset_index()\n",
    "                        .drop(columns=['index']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    50.0\n",
       "0    50.0\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the percentage of each label \n",
    "train_df.label.value_counts()/train_df.label.count()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36062, 11)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Balancing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    98.703549\n",
       "1     1.296451\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the percentage of each label \n",
    "raw_test_df.label.value_counts()/raw_test_df.label.count()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set the percent of unlabelled data required in test data (taken from complete data set)\n",
    "unlabel_test_percent = 0.9858014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# find the number of labelled datapoints in the test data\n",
    "label_test_size = raw_test_df[raw_test_df.label == 1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# compute the amount of unlabelled data required to simulate the entire dataset\n",
    "unlabelled_test_size = int((unlabel_test_percent*label_test_size)/(1-unlabel_test_percent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# isolate labelled data\n",
    "label_test_df = raw_test_df[raw_test_df.label == 1]\n",
    "\n",
    "# isolate unlabelled data\n",
    "unlabel_test_df = raw_test_df[raw_test_df.label == 0]\n",
    "\n",
    "# sample unlabelled data of the correct size\n",
    "reduced_unlabel_test_df = unlabel_test_df.sample(n=unlabelled_test_size, random_state=11)\n",
    "\n",
    "# combine to make final training data\n",
    "test_df = (pd.concat([label_test_df, reduced_unlabel_test_df])\n",
    "                        .sort_values(by=['year', 'day'])\n",
    "                        .reset_index()\n",
    "                        .drop(columns=['index']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    98.580138\n",
       "1     1.419862\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the percentage of each label \n",
    "test_df.label.value_counts()/test_df.label.count()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203893, 11)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = np.array(train_df.loc[:, 'day':])\n",
    "y = np.array(train_df.loc[:, 'label'])\n",
    "X_test = np.array(test_df.loc[:, 'day':])\n",
    "y_test = np.array(test_df.loc[:, 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36062, 7), (203893, 7))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.229874412680898"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the percent of the data used to train model\n",
    "X.shape[0]*100/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # adding polynomial features\n",
    "# poly = PolynomialFeatures(degree=2) \n",
    "\n",
    "\n",
    "# # add degree two polynomials to budget\n",
    "# X_budg = numpy.delete(poly.fit_transform(np.array(X_df[['budget']])), obj=0, axis=1) \n",
    "# X_budg_test = numpy.delete(poly.transform(np.array(X_test_df[['budget']])), obj=0, axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Cross validate a working logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-39e0a1705d73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprecisions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrecalls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mroc_aucs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'KFold' is not defined"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=3, shuffle=True, random_state = 11)\n",
    "accuracies = [] \n",
    "precisions = [] \n",
    "recalls = [] \n",
    "roc_aucs = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_ind, val_ind in kf.split(X,y):\n",
    "    \n",
    "    X_train, y_train = X[train_ind], y[train_ind]\n",
    "    X_val, y_val = X[val_ind], y[val_ind] \n",
    "    \n",
    "    lr_model = linear_model.LogisticRegression(solver=\"lbfgs\", C=100)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    y_pred = (lr_model.predict_proba(X_val)[:, 1] >= 0.49)\n",
    "    \n",
    "    accuracies.append(accuracy_score(y_val, y_pred))\n",
    "    precisions.append(precision_score(y_val, y_pred))\n",
    "    recalls.append(recall_score(y_val, y_pred))\n",
    "    roc_aucs.append(roc_auc_score(y_val, y_pred))\n",
    "    f1_scores.append(f1_score(y_val, y_pred))\n",
    "\n",
    "print(f'Accuracy: {np.mean(accuracies):.3f} +- {np.std(accuracies):.3f}')\n",
    "print(f'Precision: {np.mean(precisions):.3f} +- {np.std(precisions):.3f}')\n",
    "print(f'Recall: {np.mean(recalls):.3f} +- {np.std(recalls):.3f}')\n",
    "print(f'ROC AUC: {np.mean(roc_aucs):.3f} +- {np.std(roc_aucs):.3f}')\n",
    "print(f'F1 score: {np.mean(f1_scores):.3f} +- {np.std(f1_scores):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Threshold tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## ACCURACY PEAKS AT 0.49 BUT 0.4 MIGHT BE BETTER FOR THE SAKE OF RECALL\n",
    "for i in np.linspace(0,1,101):\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state = 11)\n",
    "    accuracies = [] \n",
    "    recalls = [] \n",
    "    \n",
    "    for train_ind, val_ind in kf.split(X,y):\n",
    "        \n",
    "        X_train, y_train = X[train_ind], y[train_ind]\n",
    "        X_val, y_val = X[val_ind], y[val_ind] \n",
    "        \n",
    "        lr_model = linear_model.LogisticRegression(solver=\"lbfgs\", C=100)\n",
    "        lr_model.fit(X_train, y_train)\n",
    "        y_pred = (lr_model.predict_proba(X_val)[:, 1] >= i)\n",
    "\n",
    "        accuracies.append(accuracy_score(y_val, y_pred))\n",
    "        recalls.append(recall_score(y_val, y_pred))\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    \n",
    "    print(f'Threshold: {i:.2f}, Accuracy: {mean_accuracy:.5f}, Recall: {mean_recall:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Tuning C-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## ACURACY AND RECALL IMPROVES WITH A C-VALUE OF 100 BUT RECALL IS BEST WITH A VERY LOW C-VALUE\n",
    "c_values = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "\n",
    "for i in c_values:\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state = 11)\n",
    "    accuracies = [] \n",
    "    recalls = [] \n",
    "    \n",
    "    for train_ind, val_ind in kf.split(X,y):\n",
    "        \n",
    "        X_train, y_train = X[train_ind], y[train_ind]\n",
    "        X_val, y_val = X[val_ind], y[val_ind] \n",
    "        \n",
    "        lr_model = linear_model.LogisticRegression(solver=\"lbfgs\", C=i)\n",
    "        lr_model.fit(X_train, y_train)\n",
    "        y_pred = (lr_model.predict_proba(X_val)[:, 1] >= 0.49)\n",
    "\n",
    "        accuracies.append(accuracy_score(y_val, y_pred))\n",
    "        recalls.append(recall_score(y_val, y_pred))\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    \n",
    "    print(f'C-value: {i}, Accuracy: {mean_accuracy:.5f}, Recall: {mean_recall:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Tuning solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## UNINTERESTING AS USUAL\n",
    "solver_choices = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "\n",
    "for i in solver_choices:\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state = 11)\n",
    "    accuracies = [] \n",
    "    recalls = [] \n",
    "    \n",
    "    for train_ind, val_ind in kf.split(X,y):\n",
    "        \n",
    "        X_train, y_train = X[train_ind], y[train_ind]\n",
    "        X_val, y_val = X[val_ind], y[val_ind] \n",
    "        \n",
    "        lr_model = linear_model.LogisticRegression(solver=i, C=100)\n",
    "        lr_model.fit(X_train, y_train)\n",
    "        y_pred = (lr_model.predict_proba(X_val)[:, 1] >= 0.49)\n",
    "\n",
    "        accuracies.append(accuracy_score(y_val, y_pred))\n",
    "        recalls.append(recall_score(y_val, y_pred))\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    \n",
    "    print(f'Solver: {i}, Accuracy: {mean_accuracy:.5f}, Recall: {mean_recall:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Train and test final logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr_model = linear_model.LogisticRegression(solver=\"lbfgs\", C=100)\n",
    "lr_model.fit(X, y)\n",
    "y_pred = (lr_model.predict_proba(X_test)[:, 1] >= 0.47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# SHAME\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.3f}')\n",
    "print(f'Precision: {precision:.3f}')\n",
    "print(f'Recall: {recall:.3f}')\n",
    "print(f'ROC AUC: {roc_auc:.3f}')\n",
    "print(f'F1 score: {f1:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Analyze features of final logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# MOST IMPORTANT FEATURES PREDICTING REMAIN ARE PAY, MIGRANT SHARE, SCOTLAND\n",
    "importances = dict(set(zip(train_df.loc[:, 'year':].columns, lr_model.coef_[0])))\n",
    "\n",
    "importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Cross validate a Gaussian naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b11b444ecadb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## GAUSSIAN HAS BETTER RECALL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mkf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprecisions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrecalls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'KFold' is not defined"
     ]
    }
   ],
   "source": [
    "## GAUSSIAN HAS BETTER RECALL\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state = 11)\n",
    "accuracies = [] \n",
    "precisions = [] \n",
    "recalls = [] \n",
    "roc_aucs = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_ind, val_ind in kf.split(X,y):\n",
    "    \n",
    "    X_train, y_train = X[train_ind], y[train_ind]\n",
    "    X_val, y_val = X[val_ind], y[val_ind] \n",
    "    \n",
    "    nb_model = naive_bayes.GaussianNB()\n",
    "    nb_model.fit(X_train, y_train)\n",
    "    y_pred = (nb_model.predict_proba(X_val)[:, 1] >= 0.99)\n",
    "    \n",
    "    accuracies.append(accuracy_score(y_val, y_pred))\n",
    "    precisions.append(precision_score(y_val, y_pred))\n",
    "    recalls.append(recall_score(y_val, y_pred))\n",
    "    roc_aucs.append(roc_auc_score(y_val, y_pred))\n",
    "    f1_scores.append(f1_score(y_val, y_pred))\n",
    "\n",
    "print(f'Accuracy: {np.mean(accuracies):.3f} +- {np.std(accuracies):.3f}')\n",
    "print(f'Precision: {np.mean(precisions):.3f} +- {np.std(precisions):.3f}')\n",
    "print(f'Recall: {np.mean(recalls):.3f} +- {np.std(recalls):.3f}')\n",
    "print(f'ROC AUC: {np.mean(roc_aucs):.3f} +- {np.std(roc_aucs):.3f}')\n",
    "print(f'F1 score: {np.mean(f1_scores):.3f} +- {np.std(f1_scores):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Cross validate a Bernoulli naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## BERNOULLI HAS BETTER ACCURACY\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state = 11)\n",
    "accuracies = [] \n",
    "precisions = [] \n",
    "recalls = [] \n",
    "roc_aucs = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_ind, val_ind in kf.split(X,y):\n",
    "    \n",
    "    X_train, y_train = X[train_ind], y[train_ind]\n",
    "    X_val, y_val = X[val_ind], y[val_ind] \n",
    "    \n",
    "    nb_model = naive_bayes.BernoulliNB()\n",
    "    nb_model.fit(X_train, y_train)\n",
    "    y_pred = (nb_model.predict_proba(X_val)[:, 1] >= 0.46)\n",
    "    \n",
    "    accuracies.append(accuracy_score(y_val, y_pred))\n",
    "    precisions.append(precision_score(y_val, y_pred))\n",
    "    recalls.append(recall_score(y_val, y_pred))\n",
    "    roc_aucs.append(roc_auc_score(y_val, y_pred))\n",
    "    f1_scores.append(f1_score(y_val, y_pred))\n",
    "\n",
    "print(f'Accuracy: {np.mean(accuracies):.3f} +- {np.std(accuracies):.3f}')\n",
    "print(f'Precision: {np.mean(precisions):.3f} +- {np.std(precisions):.3f}')\n",
    "print(f'Recall: {np.mean(recalls):.3f} +- {np.std(recalls):.3f}')\n",
    "print(f'ROC AUC: {np.mean(roc_aucs):.3f} +- {np.std(roc_aucs):.3f}')\n",
    "print(f'F1 score: {np.mean(f1_scores):.3f} +- {np.std(f1_scores):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Threshold tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## GAUSSIAN ACCURACY IS RUBBISH UNTIL ABOVE 0.8 BUT RECALL IS ALWAYS GOOD\n",
    "## BERNOULLI ACCURACY PEAKS AT 0.46 BUT RECALL IS BETTER AROUND 0.3\n",
    "for i in np.linspace(0,1,101):\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state = 11)\n",
    "    accuracies = [] \n",
    "    recalls = [] \n",
    "    \n",
    "    for train_ind, val_ind in kf.split(X,y):\n",
    "        \n",
    "        X_train, y_train = X[train_ind], y[train_ind]\n",
    "        X_val, y_val = X[val_ind], y[val_ind] \n",
    "        \n",
    "        nb_model = naive_bayes.BernoulliNB()\n",
    "        nb_model.fit(X_train, y_train)\n",
    "        y_pred = (nb_model.predict_proba(X_val)[:, 1] >= i)\n",
    "\n",
    "        accuracies.append(accuracy_score(y_val, y_pred))\n",
    "        recalls.append(recall_score(y_val, y_pred))\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    \n",
    "    print(f'Threshold: {i:.2f}, Accuracy: {mean_accuracy:.5f}, Recall: {mean_recall:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validate a working random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.736 +- 0.008\n",
      "Precision: 0.692 +- 0.009\n",
      "Recall: 0.849 +- 0.010\n",
      "ROC AUC: 0.736 +- 0.008\n",
      "F1 score: 0.763 +- 0.008\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state = 11)\n",
    "accuracies = [] \n",
    "precisions = [] \n",
    "recalls = [] \n",
    "roc_aucs = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_ind, val_ind in kf.split(X,y):\n",
    "    \n",
    "    X_train, y_train = X[train_ind], y[train_ind]\n",
    "    X_val, y_val = X[val_ind], y[val_ind] \n",
    "    \n",
    "    rf_model = ensemble.RandomForestClassifier(n_estimators=11, \n",
    "                                               random_state=11, \n",
    "                                               criterion='entropy', \n",
    "                                               max_depth=18, \n",
    "                                               min_samples_split=15, \n",
    "                                               max_features=1,\n",
    "                                               max_leaf_nodes=1000,\n",
    "                                               min_samples_leaf=11,\n",
    "                                               max_samples=0.45)\n",
    "    \n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred = (rf_model.predict_proba(X_val)[:, 1] >= 0.44)\n",
    "    \n",
    "    accuracies.append(accuracy_score(y_val, y_pred))\n",
    "    precisions.append(precision_score(y_val, y_pred))\n",
    "    recalls.append(recall_score(y_val, y_pred))\n",
    "    roc_aucs.append(roc_auc_score(y_val, y_pred))\n",
    "    f1_scores.append(f1_score(y_val, y_pred))\n",
    "\n",
    "print(f'Accuracy: {np.mean(accuracies):.3f} +- {np.std(accuracies):.3f}')\n",
    "print(f'Precision: {np.mean(precisions):.3f} +- {np.std(precisions):.3f}')\n",
    "print(f'Recall: {np.mean(recalls):.3f} +- {np.std(recalls):.3f}')\n",
    "print(f'ROC AUC: {np.mean(roc_aucs):.3f} +- {np.std(roc_aucs):.3f}')\n",
    "print(f'F1 score: {np.mean(f1_scores):.3f} +- {np.std(f1_scores):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Threshold tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## CLEAR WINNER IS 0.41 WITH BEST ACCURACY AND STILL HIGH RECALL\n",
    "## WITH 25 ESTIMATORS ACCURACY IMPROVES NEARER TO 0.5 BUT RECALL DECREASES THERE, 0.45 IS A COMPROMISE\n",
    "## WITH 25 ESTIMATORS AND ENTROPY CRITERION BEST IS ACTUALLY 0.49\n",
    "for i in np.linspace(0.3,0.6,31):\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state = 11)\n",
    "    accuracies = [] \n",
    "    recalls = [] \n",
    "    \n",
    "    for train_ind, val_ind in kf.split(X,y):\n",
    "        \n",
    "        X_train, y_train = X[train_ind], y[train_ind]\n",
    "        X_val, y_val = X[val_ind], y[val_ind] \n",
    "        \n",
    "        rf_model = ensemble.RandomForestClassifier(n_estimators=25, \n",
    "                                               random_state=11, \n",
    "                                               criterion='entropy')\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        y_pred = (rf_model.predict_proba(X_val)[:, 1] >= i)\n",
    "\n",
    "        accuracies.append(accuracy_score(y_val, y_pred))\n",
    "        recalls.append(recall_score(y_val, y_pred))\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    \n",
    "    print(f'Threshold: {i:.2f}, Accuracy: {mean_accuracy:.3f}, Recall: {mean_recall:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Number of estimators tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## BEST SEEMS TO BE 25\n",
    "for i in range(1,30):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state = 11)\n",
    "    accuracies = [] \n",
    "    recalls = [] \n",
    "    \n",
    "    for train_ind, val_ind in kf.split(X,y):\n",
    "        \n",
    "        X_train, y_train = X[train_ind], y[train_ind]\n",
    "        X_val, y_val = X[val_ind], y[val_ind] \n",
    "        \n",
    "        rf_model = ensemble.RandomForestClassifier(n_estimators=i, random_state=11, criterion='entropy')\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        y_pred = (rf_model.predict_proba(X_val)[:, 1] >= 0.45)\n",
    "\n",
    "        accuracies.append(accuracy_score(y_val, y_pred))\n",
    "        recalls.append(recall_score(y_val, y_pred))\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    \n",
    "    print(f'Number of estimators: {i}, Accuracy: {mean_accuracy:.5f}, Recall: {mean_recall:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Entropy criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## ENTROPY CRITERION SLIGHTLY IMPROVES ACCURACY AND RECALL\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 11)\n",
    "accuracies = [] \n",
    "precisions = [] \n",
    "recalls = [] \n",
    "roc_aucs = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_ind, val_ind in kf.split(X,y):\n",
    "    \n",
    "    X_train, y_train = X[train_ind], y[train_ind]\n",
    "    X_val, y_val = X[val_ind], y[val_ind] \n",
    "    \n",
    "    rf_model = ensemble.RandomForestClassifier(n_estimators=25, random_state=11, criterion='entropy')\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred = (rf_model.predict_proba(X_val)[:, 1] >= 0.45)\n",
    "    \n",
    "    accuracies.append(accuracy_score(y_val, y_pred))\n",
    "    precisions.append(precision_score(y_val, y_pred))\n",
    "    recalls.append(recall_score(y_val, y_pred))\n",
    "    roc_aucs.append(roc_auc_score(y_val, y_pred))\n",
    "    f1_scores.append(f1_score(y_val, y_pred))\n",
    "\n",
    "print(f'Accuracy: {np.mean(accuracies):.3f} +- {np.std(accuracies):.3f}')\n",
    "print(f'Precision: {np.mean(precisions):.3f} +- {np.std(precisions):.3f}')\n",
    "print(f'Recall: {np.mean(recalls):.3f} +- {np.std(recalls):.3f}')\n",
    "print(f'ROC AUC: {np.mean(roc_aucs):.3f} +- {np.std(roc_aucs):.3f}')\n",
    "print(f'F1 score: {np.mean(f1_scores):.3f} +- {np.std(f1_scores):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Max depth tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## BEST SEEMS TO BE 27\n",
    "for i in range(2,25):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state = 11)\n",
    "    accuracies = [] \n",
    "    recalls = [] \n",
    "    \n",
    "    for train_ind, val_ind in kf.split(X,y):\n",
    "        \n",
    "        X_train, y_train = X[train_ind], y[train_ind]\n",
    "        X_val, y_val = X[val_ind], y[val_ind] \n",
    "        \n",
    "        rf_model = ensemble.RandomForestClassifier(n_estimators=25, random_state=11, criterion='entropy', max_depth=i)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        y_pred = (rf_model.predict_proba(X_val)[:, 1] >= 0.45)\n",
    "\n",
    "        accuracies.append(accuracy_score(y_val, y_pred))\n",
    "        recalls.append(recall_score(y_val, y_pred))\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    \n",
    "    print(f'Max depth: {i}, Accuracy: {mean_accuracy:.5f}, Recall: {mean_recall:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Min samples split tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## BEST SEEMS TO BE 5\n",
    "for i in range(2,20):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state = 11)\n",
    "    accuracies = [] \n",
    "    recalls = [] \n",
    "    \n",
    "    for train_ind, val_ind in kf.split(X,y):\n",
    "        \n",
    "        X_train, y_train = X[train_ind], y[train_ind]\n",
    "        X_val, y_val = X[val_ind], y[val_ind] \n",
    "        \n",
    "        rf_model = ensemble.RandomForestClassifier(n_estimators=25, \n",
    "                                                   random_state=11, \n",
    "                                                   criterion='entropy', \n",
    "                                                   max_depth=27,\n",
    "                                                   min_samples_split=i)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        y_pred = (rf_model.predict_proba(X_val)[:, 1] >= 0.45)\n",
    "\n",
    "        accuracies.append(accuracy_score(y_val, y_pred))\n",
    "        recalls.append(recall_score(y_val, y_pred))\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    \n",
    "    print(f'Min samples split: {i}, Accuracy: {mean_accuracy:.5f}, Recall: {mean_recall:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Max leaf nodes tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## ACCURACY CANT BE IMPROVED WITH MAX LEAF NODES BUT RECALL IS AWESOME AT MAX LEAF NODES OF 2\n",
    "for i in range(1,20):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state = 11)\n",
    "    accuracies = [] \n",
    "    recalls = [] \n",
    "    \n",
    "    for train_ind, val_ind in kf.split(X,y):\n",
    "        \n",
    "        X_train, y_train = X[train_ind], y[train_ind]\n",
    "        X_val, y_val = X[val_ind], y[val_ind] \n",
    "        \n",
    "        rf_model = ensemble.RandomForestClassifier(n_estimators=25, \n",
    "                                                   random_state=11, \n",
    "                                                   criterion='entropy', \n",
    "                                                   max_depth=27,\n",
    "                                                   min_samples_split=5, \n",
    "                                                   max_leaf_nodes=2**i)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        y_pred = (rf_model.predict_proba(X_val)[:, 1] >= 0.45)\n",
    "\n",
    "        accuracies.append(accuracy_score(y_val, y_pred))\n",
    "        recalls.append(recall_score(y_val, y_pred))\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    \n",
    "    print(f'Max leaf nodes: {2**i}, Accuracy: {mean_accuracy:.5f}, Recall: {mean_recall:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Min samples leaf tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## DOESN'T SEEM TO HELP ACCURACY, BUT IMPROVES RECALL SLIGHTLY AT LOW NUMBERS\n",
    "for i in range(1,20):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state = 11)\n",
    "    accuracies = [] \n",
    "    recalls = [] \n",
    "    \n",
    "    for train_ind, val_ind in kf.split(X,y):\n",
    "        \n",
    "        X_train, y_train = X[train_ind], y[train_ind]\n",
    "        X_val, y_val = X[val_ind], y[val_ind] \n",
    "        \n",
    "        rf_model = ensemble.RandomForestClassifier(n_estimators=25, \n",
    "                                                   random_state=11, \n",
    "                                                   criterion='entropy', \n",
    "                                                   max_depth=27,\n",
    "                                                   min_samples_split=5, \n",
    "                                                   min_samples_leaf=i)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        y_pred = (rf_model.predict_proba(X_val)[:, 1] >= 0.45)\n",
    "\n",
    "        accuracies.append(accuracy_score(y_val, y_pred))\n",
    "        recalls.append(recall_score(y_val, y_pred))\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    \n",
    "    print(f'Min samples leaf: {i}, Accuracy: {mean_accuracy:.5f}, Recall: {mean_recall:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Max samples tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## DOESN'T SEEM TO BE HELPFUL\n",
    "for i in np.linspace(0.01,0.99,30):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state = 11)\n",
    "    accuracies = [] \n",
    "    recalls = [] \n",
    "    \n",
    "    for train_ind, val_ind in kf.split(X,y):\n",
    "        \n",
    "        X_train, y_train = X[train_ind], y[train_ind]\n",
    "        X_val, y_val = X[val_ind], y[val_ind] \n",
    "        \n",
    "        rf_model = ensemble.RandomForestClassifier(n_estimators=25, \n",
    "                                                   random_state=11, \n",
    "                                                   criterion='entropy', \n",
    "                                                   max_depth=27,\n",
    "                                                   min_samples_split=5, \n",
    "                                                   max_samples=i)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        y_pred = (rf_model.predict_proba(X_val)[:, 1] >= 0.45)\n",
    "\n",
    "        accuracies.append(accuracy_score(y_val, y_pred))\n",
    "        recalls.append(recall_score(y_val, y_pred))\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    \n",
    "    print(f'Max samples (pct of total): {i*100:.1f}, Accuracy: {mean_accuracy:.3f}, Recall: {mean_recall:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Max features tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## ACCURACY PEAKS AT 6, RECALL IS BEST AT LOWER FEATURES\n",
    "for i in range(1,9):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state = 11)\n",
    "    accuracies = [] \n",
    "    recalls = [] \n",
    "    \n",
    "    for train_ind, val_ind in kf.split(X,y):\n",
    "        \n",
    "        X_train, y_train = X[train_ind], y[train_ind]\n",
    "        X_val, y_val = X[val_ind], y[val_ind] \n",
    "        \n",
    "        rf_model = ensemble.RandomForestClassifier(n_estimators=25, \n",
    "                                                   random_state=11, \n",
    "                                                   criterion='entropy', \n",
    "                                                   max_depth=27,\n",
    "                                                   min_samples_split=5, \n",
    "                                                   max_features=i)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        y_pred = (rf_model.predict_proba(X_val)[:, 1] >= 0.45)\n",
    "\n",
    "        accuracies.append(accuracy_score(y_val, y_pred))\n",
    "        recalls.append(recall_score(y_val, y_pred))\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    \n",
    "    print(f'Max features: {i:.0f}, Accuracy: {mean_accuracy:.5f}, Recall: {mean_recall:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test final random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train best random forest model\n",
    "best_rf_model = ensemble.RandomForestClassifier(n_estimators=11, \n",
    "                                               random_state=11, \n",
    "                                               criterion='entropy', \n",
    "                                               max_depth=18, \n",
    "                                               min_samples_split=15, \n",
    "                                               max_features=1,\n",
    "                                               max_leaf_nodes=1000,\n",
    "                                               min_samples_leaf=11,\n",
    "                                               max_samples=0.45)\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "y_pred = (best_rf_model.predict_proba(X_test)[:, 1] >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2852182272074078"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see what percent were predicted to be ransomware\n",
    "np.sum(y_pred)/y_pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[144563,  56435],\n",
       "       [  1176,   1719]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.717\n",
      "Precision: 0.030\n",
      "Recall: 0.594\n",
      "ROC AUC: 0.657\n",
      "F1 score: 0.056\n"
     ]
    }
   ],
   "source": [
    "# test the final model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.3f}')\n",
    "print(f'Precision: {precision:.3f}')\n",
    "print(f'Recall: {recall:.3f}')\n",
    "print(f'ROC AUC: {roc_auc:.3f}')\n",
    "print(f'F1 score: {f1:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Analyze features of final random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# MOST IMPORTANT FEATURES PREDICTING REMAIN ARE PAY, MIGRANT SHARE, SCOTLAND\n",
    "importances = dict(set(zip(train_df.loc[:, 'day':].columns, best_rf_model.feature_importances_)))\n",
    "\n",
    "importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Gradient boosted trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state = 11)\n",
    "accuracies = [] \n",
    "precisions = [] \n",
    "recalls = [] \n",
    "roc_aucs = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_ind, val_ind in kf.split(X,y):\n",
    "    \n",
    "    X_train, y_train = X[train_ind], y[train_ind]\n",
    "    X_val, y_val = X[val_ind], y[val_ind] \n",
    "    \n",
    "    gb_model = ensemble.GradientBoostingClassifier()\n",
    "    \n",
    "    gb_model.fit(X_train, y_train)\n",
    "    y_pred = (gb_model.predict_proba(X_val)[:, 1] >= 0.5)\n",
    "    \n",
    "    accuracies.append(accuracy_score(y_val, y_pred))\n",
    "    precisions.append(precision_score(y_val, y_pred))\n",
    "    recalls.append(recall_score(y_val, y_pred))\n",
    "    roc_aucs.append(roc_auc_score(y_val, y_pred))\n",
    "    f1_scores.append(f1_score(y_val, y_pred))\n",
    "\n",
    "print(f'Accuracy: {np.mean(accuracies):.3f} +- {np.std(accuracies):.3f}')\n",
    "print(f'Precision: {np.mean(precisions):.3f} +- {np.std(precisions):.3f}')\n",
    "print(f'Recall: {np.mean(recalls):.3f} +- {np.std(recalls):.3f}')\n",
    "print(f'ROC AUC: {np.mean(roc_aucs):.3f} +- {np.std(roc_aucs):.3f}')\n",
    "print(f'F1 score: {np.mean(f1_scores):.3f} +- {np.std(f1_scores):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
